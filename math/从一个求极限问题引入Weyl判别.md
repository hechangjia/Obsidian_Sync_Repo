---
tags:
  - math
  - 实分析
  - 遍历理论
---

> [!问题]
>求极限
> $$\frac{1}{N}\sum_{n=1}^{N}|\cos(n^2)|\to \text{ ? }$$
> 

### 1. 基本的分析
当成平均值问题来处理:
1.  如果序列本身的的极限为$A$，那么其算数平均值极限也是$A$.那么$|\cos(n^2)|$其极限存在吗？不存在所以此方法失败，而且很有可能这个序列在$0,1]$闭区间内稠密.（这种猜测来自于曾经的经验,证明$\{\sin(n):n\in\mathbb{N}\}$此集合在$[-1,1]$当中稠密，根据这个问题的经验，暗示我们考虑$n^2\text{mod } 2\pi$这个序列在$[0,2\pi]$当中的行为)
2.  或许其结果等于0？我们知道Kronecker's lemma,如果$\sum_{n\geq 1}\frac{f(n)}{n^s}$收敛，那么$\lim_{x\to\infty}\frac{1}{x^s}\sum_{n\leq x}f(n)=0$.先不论$\sum_{n\geq 1}\frac{|\cos(n^2)|}{n}$是不是收敛，但是至少计算机计算的结果告诉我们，$\frac{1}{N}\sum_{n=1}^{N}|\cos(n^2)|$不像是收敛到0的结果。
### 2.是否可以转换为求和估计?
不妨换一个角度思考问题，把这一类问题都可以归类为，估计:
$$\sum_{n=1}^{N}f(n)$$的形式，对于这个问题我们可以把问题看成是,
1.  $f(x)=|\cos(x)|$然后估计$\sum f(n^2)$
2.  $g(x)=|\cos(x^2)|$然后估计$\sum g(n)$



无论是那种情况总之问题都是同一类的问题，即对一个求和的估计。这种问题第一反应当然是，如果何以得到closed form的求和，或者可以直接对求和做一些处理，那么很容易就能得到估计。但是这个问题不那么好做(如果求和好做就动用求和工具箱，而不是求和估计工具箱)。


对于这种情况，回忆一些最基本的此类问题，我们大概有这样一个处理经验：**"如果求和本身不好处理，那么可以试试用积分近似，把问题转换为对一个积分的估计，这样或许情况会有好转。"**

让我能来回顾一下这个策略指导下我们处理过的一些问题：

1.  如果是比较光滑的函数，我们可以用Euler-Maclaurin求和公式去把求和估计问题转换为积分估计问题。(参考[[和的积分估计]])比如在估计和$\sum_{n=1}^{N}\left(\frac{1}{n}-\frac{1}{n+z}\right)$ 的过程中我们便是使用了这样的技术得到了$\log(1+z)+\frac{1}{2(1+z)}+O\left(\frac{1}{(1+z)^2}\right)$的估计。但是此处使用Euler -Maclaurin的工具会出现一些问题。首先是因为$|\cos(x^2)|$这个函数它不够光滑，它只是分段光滑。其次即便是，原来的问题从$|\cos(x^2)|$变成$\cos(x^2)$，即去掉绝对值，使用E-M求和还是会有问题。因为$\int_{1}^{N}\{x-1/2\}\sin(x^2)2xdx$这个余项的精确估计并不容易，因为我们至少是需要知道$N$级别的系数的，否则怎么求极限呢?
2.  做简单的积分估计呢？比如对求和的简单积分估计，似乎只需要被求和函数可积就行。(参考[[和的积分估计]])然而别忘了，想要用$\sum_{n\in{\mathbb{Z}}:y\leq n\leq x}f(n)=\int_{y}^{x}f(t)\ dt+O(|f(x)|+|f(y)|)$的结果，我们需要保证$f$的单调性，否则$\sum_{y\leq n \le x}\cos(2\pi n)=O(x-y)$ 就是一个典型的反例,倘若按照上面的结论会得到矛盾的$O(1)$。我们此处要做的求和估计，$|\cos(n^2)|$这个被球和函数显然是震荡得厉害的。
3.  其实求和如果和Taylor展开长得像，从而我们可以把求和估计变成Taylor展开的积分余项估计也是不错。比如$\lim _{N \rightarrow \infty} e^{-N} \sum_{n=0}^N\frac{N^n}{n!}$的这个问题当中，因为求和酷似函数$e^x$的Taylor展开，从而利用带积分余项的Taylor展开，问题转换为$\int_0^N \frac{e^{x-N}}{N!}(N-x)^N d x$的估计。然而首先，本问题的求和与Taylor展开不怎么像。
4.  直接做分段估计呢？(参考[[分段估计的想法]]) $|\cos(n^2)|$有哪一项明显比较大吗(如果有可以执行分段放缩,参考问题$\lim_{n\to\infty}\frac{n+n^{1/2}+...+n^{1/n}}{n}$)？没有。它单调减少吗？(如果大致是减少的趋势，我们可以尝试Dyadic分解，然后做放缩，最简单的例子给调和数做下界估计)可惜也不是。
5.  当然还有一种联系，此联系来自于Weyl判别。这个结论说，

> [!Weyl判别]
> 如果$s_n$在闭区间$[a,b]$上**均匀分布(equidistributed)**，那么$$\frac{1}{N}\sum_{n=1}^{N}f(s_n)\to
>     \frac{1}{b-a}\int_{a}^{b}f(x)dx$$此结果对任意连续函数$f$成立。

在求关于$\frac{1}{N}\sum_{n=1}^{N}\{\pi n\}$的例子当中我们用到过这个工具,函数$f(x)=x$，$s_n=\{\pi n\}$在$[0,1]$当中均匀分布，所以极限收敛到$\int_0^1xdx =\frac{1}{2}$。在$\frac{1}{N}\sum_{n=1}^{N}|\cos(n^2)|$的这个问题当中，如果我们令$f(x):=|\cos(x)|$，我们计算$\frac{1}{2\pi}\int_{0}^{2\pi}f(x)dx=\frac{2}{\pi}$,其结果和计算机计算结果还比较吻合。

可是$n^2$是一个无界的序列，它怎么会在某个区间里面均匀分布呢？但是我们别忘了，$|\cos(x)|$是一个周期函数，于是如果令$s_n=n^2\text{ mod }2\pi$，那么$|\cos(n^2)| =|\cos(s_n)|$，而$s_n \in[0,2\pi]$，那么至少讨论$s_n$在此闭区间当中的均匀分布是一件有意义的事情了。其实这件事并不困难，它等价于证明$\{\frac{n^2}{2\pi}\}$在$[0,1]$当中是均匀分布的，这一点只需要利用Van der Corput difference theorem就可以证明(参考[[模1均匀分布于Weyl判别]]当中的第四个部分)。

更为详细的内容可以参考:[[模1均匀分布于Weyl判别]]。
### 3.为什么求和的极限能和均匀分布扯上关系呢?

1.  **分而治之**。这是分析当中的常见手法，这件事在特定的分析的语境下(比如本问题)，特指把一个函用更简单的函数做近似，然后先处理更简单的函数再把结果推广到一般。我们用什么函数可以逼近$f:[a,b]\to\mathbb{C}$呢？

#### 3.1 多项式逼近
$\forall \varepsilon >0$都存在一个多项式$\sum_{k=0}^{m_{\varepsilon}} a_{k,\varepsilon}x^k$去一致逼近函数$f(x)$,从而使得$\frac{1}{N}\sum_{n=1}^{N}f(s_n)$的极限，其实就是$$\sum_{k=0}^{m_{\varepsilon}}
    a_{k,\varepsilon}\frac{1}{N}\sum_{n=1}^{N}
    s_n^k$$的极限。稍微试验几个例子便知道应该猜测：$$\frac{1}{N}\sum_{n=1}^{N}
    s_n^k\to
    \frac{1}{k+1}$$从而我们知道$$\sum_{k=0}^{m_{\varepsilon}}
    a_{k,\varepsilon}\frac{1}{N}\sum_{n=1}^{N} s_n^k\to
    \sum_{k=0}^{m_{\varepsilon}}
    a_{k,\varepsilon}\frac{1}{k+1}$$那么后者逼近谁呢？$\int_{0}^{1}\sum_{k=0}^{m_{\varepsilon}}a_{k,\varepsilon}x^kdx = \sum_{k=0}^{m_{\varepsilon}}a_{k,\varepsilon}\frac{1}{k+1}$这不巧了吗？我们知道如果函数列一致逼近到极限函数，那么其含参数积分也逼近于极限函数的定积分。所以$$\left|\sum_{k=0}^{m_{\varepsilon}}
    a_{k,\varepsilon}\frac{1}{k+1}-\int_{0}^{1}f(x)dx\right|<\varepsilon$$不过反思一下会发现这个结果不够好。因为副产物$\frac{1}{N}\sum_{n=1}^{N}s_n^k\to \frac{1}{k+1},k\neq 0$这个结论，用起来不方便。$s_n=s(n)$的情况下，$s(x)$通常不是一个光滑函数，如果想要用Euler - Maclaurin求和公式做估计，光滑性是必要的。虽然$s(x)$可能是来自于一个光滑函数$u(x)$，比如通过$s_n= \{u_n\}$得来。然而$\frac{1}{N}\sum_{n=1}^{N}u_n^k$的极限和$\frac{1}{N}\sum_{n=1}^{N}s_n^k$不同，因此也不能对$\frac{1}{N}\sum_{n=1}^{N}u_n^k$做估计然后间接得到$\frac{1}{N}\sum_{n=1}^{N} s_n^k$的估计。
 
不过如果要把这个结论作为均匀分布的定义，倒是不错。也就是说，$s_n$是$0,1]$当中的值，然后这堆数据的k次矩的极限恰好和均匀分布(uniform distribution)的随机变量的k次矩$\frac{1}{k+1}$相等,这暗示这堆样本可能来自于一个$U(0,1)$的随机变量。

#### 3.2 用三角多项式逼近

那么对于任意连续函数都存在$\sum_{|k|\leq m_{\varepsilon}} a_{k,\varepsilon}e^{2\pi ikx}$逼近$f(x)$于是，实际上我们可以把原来的极限转换为$$\sum_{|k|\leq
    m_{\varepsilon}}
    a_{k,\varepsilon}\frac{1}{N}\sum_{n=1}^{N}e^{2\pi
    iks_n}$$试验几个例子不难发现，实际上$\frac{1}{N}\sum_{n=1}^{N}e^{2\pi iks_n}\to0,k\neq0$.最后整个三角多项式剩下$a_{0,\varepsilon}$，此结果我们继续沿用上面的方法：如果函数列一致逼近到极限函数，那么其含参数积分也逼近于极限函数的定积分$$\left|\int_{0}^{1}f(x)dx -
    a_{0,\varepsilon}\right|<\varepsilon$$因此同样可以得到结果。然后我们审查这种毕竟得到的副产物，$$\frac{1}{N}\sum_{n=1}^{N}e^{2\pi
    iks_n}\to0,k\neq
    0$$此结果比较适合做判断工具，$\frac{1}{N}\sum_{n=1}^{N}s_n^k\to0,k\neq0$这个结果不如当前的这个判断工具。因为倘若$u_n=M+s_n$,此时$\frac{1}{N}\sum_{n=1}^{N}e^{2\pi iks_n}=\frac{1}{N}\sum_{n=1}^{N}e^{2\pi iku_n}$,而后者$\frac{1}{N}\sum_{n=1}^{N}e^{2\pi iku(x)}$很可能是一个光滑函数，从而可以用Euler - Maclaurin去做估计。


#### 3.3用简单函数去做估计

也就是说存在$\sum_{k=0}^{m_{\varepsilon}}a_{k,\varepsilon}\chi_{I_{k}}(x)$因此计算极限就等于是计算$$\sum_{k=0}^{m_{\varepsilon}}
    a_{k,\varepsilon}\frac{1}{N}\sum_{n=1}^{N}
    \chi_{I_k}(s_n)$$我希望$\frac{1}{N}\sum_{n=1}^{N}\chi_{I_k}(s_n)\to m(I_k)$翻译过来就是$$\frac{\#\{s_n\in
    I_k:n=1,...,N\}}{N}\to
    m(I_k)$$这个结果也挺适合作为定义的，比如定义$[0,1]$当中任意区间都满足上述性质。则称序列为均匀分布的序列。同时因为$$\left|\sum_{k=0}^{m_{\varepsilon}}
    a_{k,\varepsilon}m(I_k)-\int_{[0,1]}f(x)dx\right|<\varepsilon$$最后也可以得到我们想要的结论。










