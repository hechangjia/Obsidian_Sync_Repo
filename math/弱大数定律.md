---
tags:
  - math
  - 概率论
---

> [!弱大数定律]
> 假设$X_1,\cdots,X_n,\cdots$是一列独立同分布的随机变量，并且$X_1$是绝对可积的，其期望为$\mu$。令$S_n:=X_1+\cdots+X_n$，那么$$\frac{S_n}{n}\xrightarrow{P} \mu$$

### 1. 基于截断的分段估计

首先如果我们假设这些随机变量的二次矩是有限的，也就是说它们的方差都是有限的，那么我们很容易通过Chebyshev不等式证明这一点:$$P\left(\left\{\omega:\left|\frac{S_n(\omega)}{n}-\mu\right|\geq \varepsilon\right\}\right)\leq \frac{V(X_1)}{n\varepsilon^2}\to 0$$但是在弱大数定律的命题当中是没有方差有限的假设的，随机变量虽然都是$L^1$的，但未必是$L^2$的，因为在概率空间当中$||f||_{L^p}\leq||f||_{L^q}$如果$q>p\geq 1$的话。所以我们必须要处理这中间的差距。

一个常用的处理手段就是"截断"(truncation):

> [!对随机变量的截断]
> $X$是一个随机变量，$M$是一个正实数，那么称$$X_{\leq M}(\omega):=\begin{cases}X(\omega)& \text{if } |X|\leq M \\ 0&\text{otherwise}\end{cases}$$定义$X-X_{\leq M}:=X_{>M}$为截断的余项。

* 其他的表示:$X_{\leq M}=X1_{|X|\leq M},X_{>M}:=X1_{|X|> M}$总之在定义了随机变量的截断以后，我们可以把随机变量写成$$X=X_{\leq M}+X_{>M}$$
* 如果是随机变量的序列我们写成$$X_n=X_{n,\leq M}+X_{n,> M}$$
这样处理的好处是，$X_{\leq M}$是一个有界的随机变量，于是很多好的集中不等式就可以直接使用。至于后面的余项，我们的处理方式就是分段估计，不过并非是通常意义上的度量空间当中的三角不等式，而是"分布函数的三角不等式"。

不失一般性，我们假设$\mu=0$,对任意的$\varepsilon>0$定义$$\lambda_{\frac{S_n}{n}}(\varepsilon):=P\left(\left\{\omega:\left|\frac{S_n(\omega)}{n}\right|\geq \varepsilon\right\}\right)$$令$S_{n,1}=\sum_{i\leq n}X_{i,\leq M},S_{n,2}=\sum_{i\leq n}X_{i,> M}$于是由分布函数的三角不等式：$$\lambda_{\frac{S_n}{n}}(\varepsilon)\leq \lambda_{\frac{S_{n,1}}{n}}(\varepsilon/2)+\lambda_{\frac{S_{n,2}}{n}}(\varepsilon/2)$$然后我们可以对右边这两个分布函数单独进行估计。

* 因为第二段更为棘手一些，第一段我们已经知道结果一定是$o(1)$，所以我们先处理第二段。此外，因为这一段的随机变量都可能是无界的，因此选择用Chebyshev不等式做估计的时候就不能选择2次矩作为上界，不过我们还是可以用一次矩，然后结合积分收敛定理(控制收敛)来完成估计。$$\begin{aligned}\lambda_{\frac{S_{n,2}}{n}}(\varepsilon/2)&=P\left(\left\{\omega:\left|\frac{\sum_{i\leq n}X_{n,> M}(\omega)}{n}\right|\geq \varepsilon/2\right\}\right)\\&\leq \frac{2}{\varepsilon}E(|X_{1,>M}|)\end{aligned}$$这里我们可以考虑控制收敛定理。因为如果我们用任意一列序列$M_k$趋于正无穷大的实数列替代$M$,我们知道函数列$|X_{1,>M_k}|\xrightarrow{a.e.}0$,那么控制收敛定理告诉我们$$E(|X_{1,>M_k}|)\to 0$$于是我们可以这样写，对任意$\delta>0$,存在一个$N_{\delta}$使得$k>N_{\delta}$的时候都有$E(|X_{1,>M_k}|)<\delta$。也就是说对任意$\delta>0$,我们总是能找到一个足够大的$M_{\delta}$使得$E(|X_{1,>M_{\delta}}|)<\delta$。
* 第一段：$$\begin{aligned}\lambda_{\frac{S_{n,1}}{n}}(\varepsilon/2)&=P\left(\left\{\omega:\left|\frac{\sum_{i\leq n}X_{n,\leq M_{\delta}}(\omega)}{n}\right|\geq \varepsilon/2\right\}\right)\\&\leq \frac{C_{\varepsilon}\sum_{i\leq n}V(X_{i,\leq M_{\delta}})}{n^2} \\&\leq \frac{C_{\varepsilon}M_{\delta}^2}{n}\end{aligned}$$也就是说$\lambda_{\frac{S_{n,1}}{n}}(\varepsilon/2)=o(1)$。
结合以上两段的估计，对任意$\delta>0$都有$$\begin{aligned}\lambda_{\frac{S_n}{n}}(\varepsilon)&\leq \lambda_{\frac{S_{n,1}}{n}}(\varepsilon/2)+\lambda_{\frac{S_{n,2}}{n}}(\varepsilon/2)\\&\leq \frac{C_{\varepsilon}M_{\delta}^2}{n}+\frac{2}{\varepsilon}\delta\end{aligned}$$于是我们知道$$\limsup_{n\to \infty}\lambda_{\frac{S_n}{n}}(\varepsilon)\leq \frac{2}{\varepsilon}\delta$$由于$\delta$是任取的，因此$$\limsup_{n\to \infty}\lambda_{\frac{S_n}{n}}(\varepsilon)=0$$这意味着$$\frac{S_n}{n}\xrightarrow{P} 0$$因此弱大数定律成立。
